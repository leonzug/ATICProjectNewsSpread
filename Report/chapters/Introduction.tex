\section{Introduction}

Misinformation represents a considerable threat for various aspects in our society. First of all, it represents one of the greatest threats for democracy and journalism\cite{Zhou2019}. Fake news are more shared on social media than real news, as it has been seen in US 2016 presidential elections\cite{Zhou2020}. The Swiss security policy report 2021\cite{swiss2021} and US national intelligence global trends 2040 report \cite{us2021} remark that misinformation represents a threat for global security and stability: both reports foresee an increase of hybrid conflicts with misinformation and cyber offensive. Misinformation may also have a strong influence on our economy. For example, a false report of United Airlines parent company's bankruptcy in 2008 cause the company's stock price to drop by 76$\%$ in a few minutes\cite{carvalho2011}. Fake news can also have tremendous effects on public health, for example considering the misinformation around vaccines\cite{Larson2017}. Finally, as it has been shown for the Japan earthquakes in 2011\cite{Hashimoto2021}, reliable news sources are crucial during catastrophes, to avoid widespread of panic or criminal activities.\\

For all these reasons, it is important to study how misinformation spreads among a society. In today's context, with internet and social media representing a powerful vector for spreading fake news, and the trend that many people gravitate towards familiar and like-minded groups which are more likely to be in conflict with each other, is particularly favourable for misinformation and opinion polarization\cite{us2021}. The goal of this paper is applying distributed systems theory to opinion dynamics in a society and study the spread of real news and fake news. In particular, we want to develop a model to investigate different scenarios and how different factors influence the steady state opinion distribution and its type (e. g. similar opinions or polarization).
Identifying misinformation spread dynamic is crucial to mitigate negative consequences with specific measures such as instruction level\cite{joanna2017} or social network intervention\cite{mahak2020}.


\subsection{Related Literature}

Misinformation spreading has been widely studied, above all in recent years with the rise of social media. An exhaustive literature review is beyond the scope of this work.\\

A two-stage process to model the spread of fake news on twitter is proposed in \cite{Murayama2021}. \cite{Rath2019} investigates the role that community structures play in the spread of fake news, using an epidemiological model approach. An epidemiological model is also used by \cite{Tambuscio2015} to analyze the spread of misinformation. \cite{Hashimoto2021} uses graph theory to study how the truthfulness of a topic influences the opinion dynamics and how it changes after a disaster. \cite{Amelkin2017} also studies a polar opinion dynamic in social network and introduce a metric to quantify the opinion propagation. The relation between social media, network heterogeneity and opinion polarization is the focus of \cite{Lee2014a} and shows that the use of social media is a predictor of network heterogeneity. In our work, we also investigate opinion polarization using the model developed. There is no unique definition of polarization and \cite{Bramsona2016} exposes 9 different definitions of polarization with the corresponding measure. Also \cite{Akoglu2014} and \cite{Matakos2017} propose a metric to quantify polarization and effective strategies to reduce it. Moreover, the dynamic of polarization is investigated in \cite{Banisch2019}, in particular how it changes with social feedback, and in \cite{Conover2011}, where the focus is put on how social media facilitate communication between communities with different political orientations. In addition to the contributions above, measures to mitigate fake news spread are studied from different points of view. \cite{mahak2020} develops a social reinforcement approach to combat the spread of fake news with an intervention model. Fake news detection has also been widely studied, for example in \cite{Vijjali2020}\cite{improved}\cite{Zhou2020}\cite{Maryam2019}. Other combat strategies rely on instruction and critical thinking \cite{joanna2017}.


\subsection{Statement of Contribution}

In this work, we developed a model to study misinformation propagation among a community. Our contribution is threefold. First, we developed an opinion dynamics model and in particular, we described the population with different personality traits (similarity, influenceability and critical thinking) and we integrated these traits in the network model. Second, we analyzed the model from a theoretical perspective and we drew conclusions on stability, connectivity and convergence for different cases. Third, we present numerical experiments to investigate which factors influence the opinion dynamics and how the opinion distribution is affected. 



