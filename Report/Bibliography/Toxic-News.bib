Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Lee2014a,
abstract = {Employing a national probability survey in 2012, this study tests relationships between social media, social network service (SNS) network heterogeneity, and opinion polarization. The results show that the use of social media is a positive predictor of the level of network heterogeneity on SNSs and that the relationship is mediated by several news-related activities, such as getting news, news posting, and talking about politics on SNSs. Testing the association between SNS network heterogeneity and polarization, this study considers 3 different dimensions of opinion polarization: partisan, ideological, and issue. The findings indicate that political discussion moderates the relationship between network heterogeneity and the level of partisan and ideological polarizations. The implications of this study are discussed. {\textcopyright} 2014 International Communication Association.},
author = {Lee, Jae Kook and Choi, Jihyang and Kim, Cheonsoo and Kim, Yonghwan},
doi = {10.1111/jcom.12077},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/socialmedia{\_}polarization.pdf:pdf},
issn = {14602466},
journal = {Journal of Communication},
number = {4},
pages = {702--722},
title = {{Social media, network heterogeneity, and opinion polarization}},
volume = {64},
year = {2014}
}
@article{Akoglu2014,
abstract = {Political inclinations of individuals (liberal vs. conservative) largely shape their opinions on several issues such as abortion, gun control, nuclear power, etc. These opinions are openly exerted in online forums, news sites, the parliament, and so on. In this paper, we address the problem of quantifying political polarity of individuals and of political issues for classification and ranking. We use signed bipartite networks to represent the opinions of individuals on issues, and formulate the problem as a node classification task. We propose a linear algorithm that exploits network effects to learn both the polarity labels as well as the rankings of people and issues in a completely unsupervised manner. Through extensive experiments we demonstrate that our proposed method provides an effective, fast, and easy-to-implement solution, while outperforming three existing baseline algorithms adapted to signed networks, on real political forum and US Congress datasets. Experiments on a wide variety of synthetic graphs with varying polarity and degree distributions of the nodes further demonstrate the robustness of our approach..},
author = {Akoglu, Leman},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/quantify{\_}polarity.pdf:pdf},
isbn = {9781577356578},
journal = {Proceedings of the 8th International Conference on Weblogs and Social Media, ICWSM 2014},
keywords = {Full Papers},
pages = {2--11},
title = {{Quantifying political polarity based on bipartite opinion networks}},
year = {2014}
}
@article{Amelkin2017,
abstract = {Modeling and predicting people's opinions plays an important role in today's life. For viral marketing and political strategy design, it is particularly important to be able to analyze competing opinions, such as pro-Democrat vs. pro-Republican. While observing the evolution of polar opinions in a social network over time, can we tell when the network "behaved"' abnormally? Furthermore, can we predict how the opinions of individual users will change in the future? To answer such questions, it is insufficient to study individual user behavior, since opinions spread beyond users' ego-networks. Instead, we need to consider the opinion dynamics of all users simultaneously. In this work, we introduce the Social Network Distance (SND)-A distance measure that quantifies the likelihood of evolution of one snapshot of a social network into another snapshot under a chosen opinion dynamics model. SND has a rich semantics of a transportation problem, yet, is computable in pseudo-linear time, thereby, being applicable to large-scale social networks analysis.We demonstrate the effectiveness of SND in experiments with Twitter data.},
archivePrefix = {arXiv},
arxivId = {1510.05058},
author = {Amelkin, Victor and Bogdanov, Petko and Singh, Ambuj K.},
doi = {10.1109/ICDE.2017.64},
eprint = {1510.05058},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/distance{\_}measure{\_}polar.pdf:pdf},
isbn = {9781509065431},
issn = {10844627},
journal = {Proceedings - International Conference on Data Engineering},
pages = {159--162},
title = {{A distance measure for the analysis of polar opinion dynamics in social networks}},
year = {2017}
}
@inproceedings{Tambuscio2015,
abstract = {The Internet and online social networks have greatly facili- tated and accelerated information difiusion processes, but at the same time they provide fertile ground for the spread of misinformation, rumors and hoaxes. The goal of this work is to introduce a simple modeling framework to study the difiusion of hoaxes and in particular how the availability of debunking information may contain their difiusion. As tra- ditionally done in the mathematical modeling of information difiusion processes, we regard hoaxes as viruses: users can become infected if they are exposed to them, and turn into spreaders as a consequence. Upon veri cation, users can also turn into non-believers and spread the same attitude with a mechanism analogous to that of the hoax-spreaders. Both believers and non-believers, as time passes, can return to a susceptible state. Our model is characterized by four pa- rameters: spreading rate, gullibility, probability to verify a hoax, and that to forget one's current belief. Simulations on homogeneous, heterogeneous, and real networks for a wide range of parameters values reveal a threshold for the fact- checking probability that guarantees the complete removal of the hoax from the network. Via a meanfield approxima- tion, we establish that the threshold value does not depend on the spreading rate but only on the gullibility and for- getting probability. Our approach allows to quantitatively gauge the minimal reaction necessary to eradicate a hoax.},
author = {Tambuscio, Marcella and Ruffo, Giancarlo and Flammini, Alessandro and Menczer, Filippo},
booktitle = {International World Wide Web Conference},
doi = {10.1145/2740908.2742572},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/hoax.pdf:pdf},
isbn = {9781450334730},
keywords = {contact author,di,email,epidemi-,fact-checking,information diffusion models,it,misinformation spread,ology,tambuscio,unito,viral hoaxes},
title = {{Fact-checking Effect on Viral Hoaxes}},
year = {2015}
}
@article{Banisch2019,
abstract = {We explore a new mechanism to explain polarization phenomena in opinion dynamics in which agents evaluate alternative views on the basis of the social feedback obtained on expressing them. High support of the favored opinion in the social environment is treated as a positive feedback which reinforces the value associated to this opinion. In connected networks of sufficiently high modularity, different groups of agents can form strong convictions of competing opinions. Linking the social feedback process to standard equilibrium concepts we analytically characterize sufficient conditions for the stability of bi-polarization. While previous models have emphasized the polarization effects of deliberative argument-based communication, our model highlights an affective experience-based route to polarization, without assumptions about negative influence or bounded confidence.},
archivePrefix = {arXiv},
arxivId = {1704.02890},
author = {Banisch, S. and Olbrich, E.},
doi = {10.1080/0022250X.2018.1517761},
eprint = {1704.02890},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/Opinion polarization by learning from social feedback.pdf:pdf},
issn = {15455874},
journal = {Journal of Mathematical Sociology},
keywords = {Computational Sociology,Opinion Formation,Polarization,Reinforcement Learning,Social Feedback},
number = {2},
pages = {76--103},
publisher = {Routledge},
title = {{Opinion polarization by learning from social feedback}},
url = {https://doi.org/10.1080/0022250X.2018.1517761},
volume = {43},
year = {2019}
}
@techreport{swiss2021,
author = {{Swiss Confederation}},
institution = {Swiss Confederation},
title = {{Die Sicherheitspolitik der Schweiz}},
year = {2021}
}
@article{Matakos2017,
abstract = {The polarization of society over controversial social issues has been the subject of study in social sciences for decades (Isenberg in J Personal Soc Psychol 50(6):1141–1151, 1986, Sunstein in J Polit Philos 10(2):175–195, 2002). The widespread usage of online social networks and social media, and the tendency of people to connect and interact with like-minded individuals has only intensified the phenomenon of polarization (Bakshy et al. in Science 348(6239):1130–1132, 2015). In this paper, we consider the problem of measuring and reducing polarization of opinions in a social network. Using a standard opinion formation model (Friedkin and Johnsen in J Math Soc 15(3–4):193–206, 1990), we define the polarization index, which, given a network and the opinions of the individuals in the network, it quantifies the polarization observed in the network. Our measure captures the tendency of opinions to concentrate in network communities, creating echo-chambers. Given this numeric measure of polarization, we then consider the problem of reducing polarization in the network by convincing individuals (e.g., through education, exposure to diverse viewpoints, or incentives) to adopt a more neutral stand towards controversial issues. We formally define the ModerateInternal and ModerateExpressed problems, and we prove that both our problems are NP-hard. By exploiting the linear-algebraic characteristics of the opinion formation model we design polynomial-time algorithms for both problems. Our experiments with real-world datasets demonstrate the validity of our metric, and the efficiency and the effectiveness of our algorithms in practice.},
author = {Matakos, Antonis and Terzi, Evimaria and Tsaparas, Panayiotis},
doi = {10.1007/s10618-017-0527-9},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/Matakos2017{\_}Article{\_}MeasuringAndModeratingOpinionP.pdf:pdf},
isbn = {1061801705},
issn = {1573756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Moderation,Opinion formation,Polarization,Social networks},
number = {5},
pages = {1480--1505},
publisher = {Springer US},
title = {{Measuring and moderating opinion polarization in social networks}},
volume = {31},
year = {2017}
}
@techreport{us2021,
author = {{US National Intelligence Council}},
institution = {US National Intelligence Council},
title = {{Global Trends 2040}},
year = {2021}
}
@inproceedings{Maryam2019,
abstract = {Online social networks have turned out to be the most popular and most efficacious platform of information exchange among the peoples of this new era. The emergence of the social networking sites like Facebook, Tumblr, Google+ etc has completely transformed the way we pursue and share information. These social networks on one part provide a favourable platform for the widespread diffusion of news and bulletins across the globe. While on the contrary part these platforms may also become a channel for the spreading of malicious rumours and misinformation throughout the social network. Therefore, to assure the trustworthiness of content sharing in online social networks, most importantly we need to investigate the sources injecting misinformation into the network so that we can monitor these sources in future.In this paper, we aim to handle the problem of misinformation diffusion in the online social networks. We contemplate a social network where some misinformation has already been spread over the network and we are able to find the set of sources contaminated by the misinformation spread. Thus, we initiate a heuristic Source Identification to find the suspected source responsible for this misleading spread. To support the potency of our contribution, we carried out our experiments on real world Epinions social network and compared it with the contributions made by Amorouso et al. [3].},
author = {Maryam, Amrah and Ali, Rashid},
booktitle = {IEEE 5th International Conference for Convergence in Technology},
doi = {10.1109/I2CT45611.2019.9033558},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/misinformation{\_}source{\_}id.pdf:pdf},
isbn = {9781538680759},
keywords = {Independent Cascade Model,Misinformation Diffusion,Online Social Networks,Single Source Identification},
pages = {1--5},
publisher = {IEEE},
title = {{Misinformation Source Identification in an Online Social Network}},
year = {2019}
}
@article{Rath2019,
abstract = {Understanding the spread of false information in social networks has gained a lot of recent attention. In this paper, we explore the role community structures play in determining how people get exposed to fake news. Inspired by approaches in epidemiology, we propose a novel Community Health Assessment model, whose goal is to understand the vulnerability of communities to fake news spread. We define the concepts of neighbor, boundary and core nodes of a community and propose appropriate metrics to quantify the vulnerability of nodes (individual-level) and communities (group-level) to spreading fake news. We evaluate our model on communities identified using three popular community detection algorithms for twelve real-world news spreading networks collected from Twitter. Experimental results show that the proposed metrics perform significantly better on the fake news spreading networks than on the true news, indicating that our community health assessment model is effective.},
author = {Rath, Bhavtosh and Gao, Wei and Srivastava, Jaideep},
doi = {10.1145/3341161.3342920},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/spread{\_}fake{\_}society.pdf:pdf},
isbn = {9781450368681},
journal = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2019},
pages = {432--435},
title = {{Evaluating vulnerability to fake news in social networks: A community health assessment model}},
year = {2019}
}
@article{improved,
abstract = {Fake news dissemination is a critical issue in today's fast-changing network environment. Existing classification models for fake news detection have not completely stopped the spread because of their inability to accurately classify news, thus leading to a high false alarm rate. This study proposed a model that can accurately identify and classify deceptive news articles content infused on social media by malicious users. The news content, social-context features and the respective classification of reported news was extracted from the PHEME dataset using entropy-based feature selection. The selected features were normalized using Min-Max Normalization techniques. A predictive fake news detection model was formulated as a stacked ensemble of three algorithms. The model was simulated and its performance was evaluated by benchmarking with an existing model using detection accuracy, sensitivity, and precision as metrics. The result of the evaluation showed a higher 17.25{\%} detection accuracy, 15.78{\%} sensitivity, but lesser 0.2{\%} precision than the existing model. Thus, the proposed model detects more fake news instances accurately based on news content and social content perspectives. This indicates that the proposed classification model has a better detection rate, reduces the false alarm rate of news instances and thus detects fake news more accurately.},
author = {Akinyemi, Bodunde and Adewusi, Oluwakemi and Oyebade, Adedoyin},
doi = {10.5815/ijitcs.2020.01.05},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/fake{\_}news{\_}early{\_}detection3.pdf:pdf},
issn = {20749007},
journal = {International Journal of Information Technology and Computer Science},
number = {1},
pages = {34--43},
title = {{An Improved Classification Model for Fake News Detection in Social Media}},
volume = {12},
year = {2020}
}
@article{Vijjali2020,
abstract = {The rapid advancement of technology in online communication via social media platforms has led to a prolific rise in the spread of misinformation and fake news. Fake news is especially rampant in the current COVID-19 pandemic, leading to people believing in false and potentially harmful claims and stories. Detecting fake news quickly can alleviate the spread of panic, chaos and potential health hazards. We developed a two stage automated pipeline for COVID-19 fake news detection using state of the art machine learning models for natural language processing. The first model leverages a novel fact checking algorithm that retrieves the most relevant facts concerning user claims about particular COVID-19 claims. The second model verifies the level of truth in the claim by computing the textual entailment between the claim and the true facts retrieved from a manually curated COVID-19 dataset. The dataset is based on a publicly available knowledge source consisting of more than 5000 COVID-19 false claims and verified explanations, a subset of which was internally annotated and cross-validated to train and evaluate our models. We evaluate a series of models based on classical text-based features to more contextual Transformer based models and observe that a model pipeline based on BERT and ALBERT for the two stages respectively yields the best results.},
archivePrefix = {arXiv},
arxivId = {2011.13253},
author = {Vijjali, Rutvik and Potluri, Prathyush and Kumar, Siddharth and Teki, Sundeep},
eprint = {2011.13253},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/fake{\_}news{\_}early{\_}detection2.pdf:pdf},
journal = {CoRR},
title = {{Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking}},
url = {http://arxiv.org/abs/2011.13253},
volume = {13253},
year = {2020}
}
@article{Friedkin1990,
abstract = {In this paper we describe an approach to the relationship between a network of interpersonal influences and the content of individuals' opinions. Our work starts with the specification of social process rather than social equilibrium. Several models of social influence that have appeared in the literature are derived as special cases of the approach. Some implications for theories on social conflict and conformity also are developed in this paper. {\textcopyright} 1990, Taylor {\&} Francis Group, LLC. All rights reserved.},
author = {Friedkin, Noah E. and Johnsen, Eugene C.},
doi = {10.1080/0022250X.1990.9990069},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/opinion{\_}model.pdf:pdf},
issn = {15455874},
journal = {The Journal of Mathematical Sociology},
keywords = {Conflict,conformity,consensus,influence,network,opinion},
number = {3-4},
pages = {193--206},
title = {{Social influence and opinions}},
volume = {15},
year = {1990}
}
@article{Hashimoto2021,
abstract = {During a disaster, social media can be both a source of help and of danger: Social media has a potential to diffuse rumors, and officials involved in disaster mitigation must react quickly to the spread of rumor on social media. In this paper, we investigate how topic diversity (i.e., homogeneity of opinions in a topic) depends on the truthfulness of a topic (whether it is a rumor or a non-rumor) and how the topic diversity changes in time after a disaster. To do so, we develop a method for quantifying the topic diversity of the tweet data based on text content. The proposed method is based on clustering a tweet graph using Data polishing that automatically determines the number of subtopics. We perform a case study of tweets posted after the East Japan Great Earthquake on March 11, 2011. We find that rumor topics exhibit more homogeneity of opinions in a topic during diffusion than non-rumor topics. Furthermore, we evaluate the performance of our method and demonstrate its improvement on the runtime for data processing over existing methods.},
author = {Hashimoto, Takako and Shepard, David Lawrence and Kuboyama, Tetsuji and Shin, Kilho and Kobayashi, Ryota and Uno, Takeaki},
doi = {10.1007/s11227-020-03433-5},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/Hashimoto2021{\_}Article{\_}AnalyzingTemporalPatternsOfTop.pdf:pdf},
isbn = {0123456789},
issn = {15730484},
journal = {Journal of Supercomputing},
keywords = {Community detection,Data polishing,Graph clustering,Social media analysis,Topic extraction},
number = {5},
pages = {4375--4388},
publisher = {Springer US},
title = {{Analyzing temporal patterns of topic diversity using graph clustering}},
url = {https://doi.org/10.1007/s11227-020-03433-5},
volume = {77},
year = {2021}
}
@article{Bramsona2016,
abstract = {This article distinguishes nine senses of polarization and provides formal measures for each one to refine the methodology used to describe polarization in distributions of attitudes. Each distinct concept is explained through a definition, formal measures, examples, and references. We then apply these measures to GSS data regarding political views, opinions on abortion, and religiosity—topics described as revealing social polarization. Previous breakdowns of polarization include domain-specific assumptions and focus on a subset of the distribution's features. This has conflated multiple, independent features of attitude distributions. The current work aims to extract the distinct senses of polarization and demonstrate that by becoming clearer on these distinctions we can better focus our efforts on substantive issues in social phenomena.},
author = {Bramsona, Aaron and Grim, Patrick and Singer, Daniel J. and Fisher, Steven and Berger, William and Sack, Graham and Flocken, Carissa},
doi = {10.1080/0022250X.2016.1147443},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/polar{\_}definitions.pdf:pdf},
issn = {15455874},
journal = {Journal of Mathematical Sociology},
keywords = {Belief aggregation,Formal epistemology,Measurement,Polarization,Social epistemology},
number = {2},
pages = {80--111},
publisher = {Routledge},
title = {{Disambiguation of social polarization concepts and measures}},
url = {http://dx.doi.org/10.1080/0022250X.2016.1147443},
volume = {40},
year = {2016}
}
@article{Zhou2020,
abstract = {Massive dissemination of fake news and its potential to erode democracy has increased the demand for accurate fake news detection. Recent advancements in this area have proposed novel techniques that aim to detect fake news by exploring how it propagates on social networks. Nevertheless, to detect fake news at an early stage, i.e., when it is published on a news outlet but not yet spread on social media, one cannot rely on news propagation information as it does not exist. Hence, there is a strong need to develop approaches that can detect fake news by focusing on news content. In this article, a theory-driven model is proposed for fake news detection. The method investigates news content at various levels: lexicon-level, syntax-level, semantic-level, and discourse-level. We represent news at each level, relying on well-established theories in social and forensic psychology. Fake news detection is then conducted within a supervised machine learning framework. As an interdisciplinary research, our work explores potential fake news patterns, enhances the interpretability in fake news feature engineering, and studies the relationships among fake news, deception/disinformation, and clickbaits. Experiments conducted on two real-world datasets indicate the proposed method can outperform the state-of-the-art and enable fake news early detection when there is limited content information.},
author = {Zhou, Xinyi and Jain, Atishay and Phoha, Vir V. and Zafarani, Reza},
doi = {10.1145/3377478},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/fake{\_}news{\_}early{\_}detection.pdf:pdf},
issn = {2692-1626},
journal = {Digital Threats: Research and Practice},
number = {2},
pages = {1--25},
title = {{Fake News Early Detection}},
volume = {1},
year = {2020}
}
@article{carvalho2011,
author = {Carvalho, C and Klagge, N and Moench, E},
journal = {Journal of Empirical Finance},
pages = {597--615},
title = {{The persistent effects of a false news shock}},
volume = {18},
year = {2011}
}
@inproceedings{Zhou2019,
author = {Zafarani, Reza and Zho, Xinyi and Shu, Kai and Liu, Huan},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery {\&} Data Mining},
pages = {3207--3208},
title = {{Fake news research: Theories, detection strategies, and open problems}},
year = {2019}
}
@inproceedings{mahak2020,
author = {Mahak, Goindani and Neville, Jennifer},
booktitle = {Uncertainty in Artificial Intelligence Conference},
pages = {1006--1016},
title = {{Social Reinforcement Learning to Combat Fake News Spread}},
year = {2020}
}
@inproceedings{Conover2011,
abstract = {Although many studies have illustrated AI-based simulation, the concept of combining databases with AI and simulation is relatively new. Complementing AI and simulation with databases aids in the development of a completely integrated simulation environment that spans the whole simulation life cycle. This study illustrates the design of a simulation program generator, the intelligent simulation code generator (ISCG), which uses a database management system as the user-oriented interface, an object-oriented system to develop the knowledge base and simulation environment, and a target simulation language as the simulation software. The ISCG offers data independence, system independence, simulation-specific transparency, and target language neutrality. Furthermore, the ISCG offers system design flexibility.},
author = {Conover, M. D. and Ratkiewicz, J. and Francisco, M. and Goncalves, B. and Flammini, A. and Menczer, F.},
booktitle = {AAAI Conference on Weblogs and Social Media},
doi = {10.1023/A:1018556721104},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/political{\_}pol{\_}twitter.pdf:pdf},
issn = {09565515},
keywords = {Artificial intelligence,Database management system,Object oriented paradigm,Simulation,Simulation program generation},
title = {{Political Polarization on Twitter}},
year = {2011}
}
@article{Larson2017,
author = {Larson, Heidi J.},
journal = {Nature},
number = {7726},
pages = {309},
title = {{The biggest pandemic risk? Viral misinformation}},
volume = {562},
year = {2018}
}
@article{joanna2017,
author = {Burkardt, Joanna M.},
journal = {Library Technology Reports},
number = {8},
title = {{Combatig Fake News in the Digital Age}},
volume = {53},
year = {2021}
}
@article{Murayama2021,
abstract = {Fake news can have a significant negative impact on society because of the growing use of mobile devices and the worldwide increase in Internet access. It is therefore essential to develop a simple mathematical model to understand the online dissemination of fake news. In this study, we propose a point process model of the spread of fake news on Twitter. The proposed model describes the spread of a fake news item as a two-stage process: initially, fake news spreads as a piece of ordinary news; then, when most users start recognizing the falsity of the news item, that itself spreads as another news story. We validate this model using two datasets of fake news items spread on Twitter. We show that the proposed model is superior to the current state-of-the-art methods in accurately predicting the evolution of the spread of a fake news item. Moreover, a text analysis suggests that our model appropriately infers the correction time, i.e., the moment when Twitter users start realizing the falsity of the news item. The proposed model contributes to understanding the dynamics of the spread of fake news on social media. Its ability to extract a compact representation of the spreading pattern could be useful in the detection and mitigation of fake news.},
archivePrefix = {arXiv},
arxivId = {2007.14059},
author = {Murayama, Taichi and Wakamiya, Shoko and Aramaki, Eiji and Kobayashi, Ryota},
doi = {10.1371/journal.pone.0250419},
eprint = {2007.14059},
file = {:C$\backslash$:/DOCUMENTI/ETH/Master/4. Semestre Msc/Distributed Systems and Control/ProjectDistributedControl/model{\_}spread{\_}twitter.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {4 April},
pages = {1--16},
pmid = {33886665},
title = {{Modeling the spread of fake news on Twitter}},
url = {http://dx.doi.org/10.1371/journal.pone.0250419},
volume = {16},
year = {2021}
}
